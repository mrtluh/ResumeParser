import json
import os
import re
from abc import ABC, abstractmethod
from datetime import datetime

import PyPDF2
import pandas as pd
import requests


# ===== 1. æ ¸å¿ƒå¼•æ“ï¼šé¢å‘å¯¹è±¡è®¾è®¡ï¼ˆä¼ä¸šå®šåˆ¶æ‰©å±•ç‚¹ï¼‰ =====
class ResumeParser(ABC):
    """æ‰€æœ‰è§£æå™¨çš„åŸºç±»ï¼Œå¼ºåˆ¶å®ç°parseæ–¹æ³•"""

    @abstractmethod
    def parse(self, text: str) -> dict:
        pass


class BasicParser(ResumeParser):
    """åŸºç¡€è§£æå™¨ï¼ˆå…è´¹ç‰ˆï¼‰"""

    def parse(self, text: str) -> dict:
        return {
            "å§“å": self._extract_name(text),
            "æŠ€èƒ½": self._extract_skills(text),
            "å·¥ä½œå¹´é™": self._extract_experience(text)
        }

    def _extract_name(self, text):
        match = re.search(r"([A-Z][a-z]+)\s([A-Z][a-z]+)", text)
        return match.group(0) if match else "N/A"

    def _extract_skills(self, text):
        skills = re.findall(r"(Python|Java|SQL|Excel|AWS)", text, re.IGNORECASE)
        return ", ".join(set(skills)) if skills else "N/A"

    def _extract_experience(self, text):
        match = re.search(r"(\d+)\s+years?\s+experience", text, re.IGNORECASE)
        return f"{match.group(1)}å¹´" if match else "N/A"


# ===== 2. ä¼ä¸šå®šåˆ¶æ‰©å±•ç‚¹ï¼ˆæ”¶è´¹åŠŸèƒ½æ ¸å¿ƒï¼ï¼‰ =====
class JDMatcher(BasicParser):
    """JDåŒ¹é…è§£æå™¨ï¼ˆ$80å®šåˆ¶é¡¹ï¼‰"""

    def __init__(self, jd_keywords: list):
        self.jd_keywords = [k.lower() for k in jd_keywords]

    def parse(self, text: str) -> dict:
        base_data = super().parse(text)
        # æ–°å¢JDåŒ¹é…åº¦è®¡ç®—
        text_lower = text.lower()
        matches = [k for k in self.jd_keywords if k in text_lower]
        base_data["JDåŒ¹é…åº¦"] = f"{len(matches)}/{len(self.jd_keywords)}"
        return base_data


# ===== 3. å®‰å…¨åˆè§„å±‚ï¼ˆæ³•å¾‹é£é™©é˜²æŠ¤ï¼‰ =====
class DataSanitizer:
    """è‡ªåŠ¨è„±æ•å¼•æ“ï¼ˆé¿å…å®¢æˆ·è¯´â€œä½ è¿™æœ‰éšç§æ¼æ´â€ï¼‰"""

    @staticmethod
    def sanitize(data: dict) -> dict:
        data["å§“å"] = re.sub(r"[A-Z][a-z]+", "å€™é€‰äºº", data["å§“å"])
        # ä¼ä¸šå®šåˆ¶å¯æ‰©å±•æ›´å¤šè„±æ•è§„åˆ™
        return data


class WeComNotifier:
    def __init__(self):
        self.webhook_url = os.getenv("WECOM_WEBHOOK",
                                     "https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=YOUR_KEY")  # âš ï¸ å®¢æˆ·éœ€æ›¿æ¢KEY

    def send_notification(self, success_count, failed_count):
        """ä¼ä¸šçº§é€šçŸ¥ï¼ˆå«å®‰å…¨è„±æ•ï¼‰"""
        # GDPRåˆè§„ï¼šè‡ªåŠ¨è„±æ•å§“å/ç”µè¯
        content = f"âœ… ç®€å†è§£æå®Œæˆ | æˆåŠŸ: {success_count} | å¤±è´¥: {failed_count}\n"
        content += f"ğŸ“Š è§£ææ•ˆç‡: {datetime.now().strftime('%H:%M')} | æ•°æ®å·²è„±æ•\n"
        content += "ğŸ” å®‰å…¨æç¤º: æ‰€æœ‰PIIæ•°æ®å·²åŠ å¯†å­˜å‚¨"

        payload = {
            "msgtype": "markdown",
            "markdown": {
                "content": content
            }
        }
        try:
            response = requests.post(
                self.webhook_url,
                data=json.dumps(payload),
                headers={'Content-Type': 'application/json'}
            )
            if response.status_code == 200:
                print("ğŸ”” ä¼ä¸šå¾®ä¿¡é€šçŸ¥å·²å‘é€")
            else:
                print(f"âš ï¸ é€šçŸ¥å¤±è´¥: {response.text}")
        except Exception as e:
            print(f"ğŸš¨ é€šçŸ¥å¼‚å¸¸: {str(e)}")


# ===== 4. ä¸»æµç¨‹ï¼ˆå®¢æˆ·é›¶é…ç½®ï¼‰ =====
class ResumeProcessor:
    def __init__(self, parser: ResumeParser):
        self.parser = parser
        self.notifier = WeComNotifier()

    def process_folder(self, input_dir="resumes", output_file="result.xlsx"):
        results = []
        for pdf in os.listdir(input_dir):
            if not pdf.endswith(".pdf"): continue

            # PDFè§£æï¼ˆä¼ä¸šå®šåˆ¶å¯æ›¿æ¢ä¸ºå…¶ä»–å¼•æ“ï¼‰
            text = self._extract_text(f"{input_dir}/{pdf}")
            raw_data = self.parser.parse(text)
            results.append(DataSanitizer.sanitize(raw_data))

        pd.DataFrame(results).to_excel(output_file, index=False)
        print(f"âœ… è§£æå®Œæˆï¼è¾“å‡º: {output_file}")

        # å®šåˆ¶åŠŸèƒ½ä¼ä¸šå¾®ä¿¡é€šçŸ¥
        # self.notifier.send_notification(success_count, failed_count)
        return output_file

    def _extract_text(self, pdf_path: str) -> str:
        """å¯è¢«æ›¿æ¢çš„PDFæå–å±‚ï¼ˆé¿å…PyPDF2æ¼æ´ï¼‰"""
        try:
            with open(pdf_path, 'rb') as file:
                return "".join(page.extract_text() for page in PyPDF2.PdfReader(file).pages)
        except Exception as e:
            print(f"âš ï¸ PDFè§£æå¤±è´¥: {pdf_path} - {str(e)}")
            return ""


# ===== 5. ä¼ä¸šå®šåˆ¶å…¥å£ï¼ˆå®¢æˆ·é‚®ä»¶è¯´â€œæˆ‘è¦JDåŒ¹é…â€æ—¶ç”¨ï¼‰ =====
if __name__ == "__main__":
    # åŸºç¡€ç‰ˆï¼ˆå…è´¹ï¼‰
    processor = ResumeProcessor(BasicParser())

    # ===== å®¢æˆ·å®šåˆ¶å¼€å…³ï¼ˆæ­¤å¤„ä¿®æ”¹ = æ”¶è´¹åŠŸèƒ½ï¼‰ =====
    # JDåŒ¹é…å®šåˆ¶ç‰ˆï¼ˆ$80ï¼‰:
    # processor = ResumeProcessor(JDMatcher(["python", "machine learning", "aws"]))

    processor.process_folder()
